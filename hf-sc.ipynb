{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys, os, time\n",
    "import itertools\n",
    "import copy\n",
    "import warnings\n",
    "import time\n",
    "import math\n",
    "# scientific computing libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "from scipy.sparse import coo_matrix, csc_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import BPoly\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# third party libraries\n",
    "import mosek\n",
    "from tabulate import tabulate\n",
    "\n",
    "from libott import loadTGP, construct_P, construct_A, gradient_from_P, gradient_from_A, set_print_level\n",
    "from libbezier import Bezier\n",
    "\n",
    "DO_PLOT_RESULTS = True\n",
    "\n",
    "\n",
    "def print_green(*args, **kwargs):\n",
    "    print(\"\\033[1;32m\", end='')\n",
    "    print(*args, **kwargs)\n",
    "    print(\"\\033[0m\", end='')\n",
    "\n",
    "def print_yellow(*args, **kwargs):\n",
    "    print(\"\\033[1;33m\", end='')\n",
    "    print(*args, **kwargs)\n",
    "    print(\"\\033[0m\", end ='')\n",
    "\n",
    "def print_purple(*args, **kwargs):\n",
    "    print(\"\\033[1;34m\", end='')\n",
    "    print(*args, **kwargs)\n",
    "    print(\"\\033[0m\", end='')\n",
    "\n",
    "def print_red(*args, **kwargs):\n",
    "    print(\"\\033[1;35m\", end='')\n",
    "    print(*args, **kwargs)\n",
    "    print(\"\\033[0m\", end='')\n",
    "\n",
    "def print_cyan(*args, **kwargs):\n",
    "    print(\"\\033[1;36m\", end='')\n",
    "    print(*args, **kwargs)\n",
    "    print(\"\\033[0m\", end='')\n",
    "\n",
    "def print_gray(*args, **kwargs):\n",
    "    print(\"\\033[1;37m\", end='')\n",
    "    print(*args, **kwargs)\n",
    "    print(\"\\033[0m\", end='')\n",
    "\n",
    "\n",
    "class IndoorOptProblem(object):\n",
    "    \"\"\"Convex optimization around corridor approach for drone trajectory optimization.\n",
    "\n",
    "    Currently it support problem where each corridor has been specified a time, later we will let it be free.\n",
    "    \"\"\"\n",
    "    def __init__(self, tgp, tfweight=0, connect_order=2, verbose=False):\n",
    "        \"\"\"Constructor for this problem class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tgp: a PyTGProblem object.\n",
    "        tfweight: float, the weight on transfer time\n",
    "        connect_order: to which order of derivative at connection do we guarantee continuity.\n",
    "        verbose: bool, if the solver is verbose\n",
    "        \"\"\"\n",
    "        self.floor = tgp  # I shall still use the floor name for convenience\n",
    "        self.x0_pack = [tgp.position[0], tgp.velocity[0], tgp.acceleration[0]]\n",
    "        self.xf_pack = [tgp.position[1], tgp.velocity[1], tgp.acceleration[1]]\n",
    "        self.tfweight = tfweight\n",
    "        self.obj_order = tgp.minimizeOrder\n",
    "        self.poly_order = tgp.trajectoryOrder\n",
    "        self.connect_order = connect_order  # guarantee acceleration continuity\n",
    "        self.verbose = verbose\n",
    "        self.margin = tgp.margin\n",
    "        self.is_limit_vel = tgp.doLimitVelocity\n",
    "        self.is_limit_acc = tgp.doLimitAcceleration\n",
    "        self.vel_limit = tgp.maxVelocity  # component wise limit on velocity\n",
    "        self.acc_limit = tgp.maxAcceleration  # component wise limit on acceleration\n",
    "        # get info on environment\n",
    "        self.boxes = tgp.getCorridor()\n",
    "        self.num_box = len(self.boxes)\n",
    "        self.room_time = np.array([box.t for box in self.boxes])\n",
    "        bz = Bezier(self.poly_order, self.poly_order, self.obj_order)\n",
    "        self.bz = bz\n",
    "        self.bzM = self.bz.M()[self.poly_order]  # use this for some output stuff\n",
    "        self.MQM = self.bz.MQM()[self.poly_order]\n",
    "        self.h_type = \"l\"\n",
    "        if verbose:\n",
    "            print('has %d boxes' % self.num_box)\n",
    "            print('init time ', self.room_time)\n",
    "        # some default settings such as how close you can reach the corner\n",
    "        self.abs_obj_tol = 1e-3  # this controls absolute objective tolerance and should not set small for problem with small obj\n",
    "        self.rel_obj_tol = 5e-4  # this controls relative objective tolerance\n",
    "        self.grad_tol = 1e-3  # this controls gradient tolerance\n",
    "        self.r = 0.0001  # 0.00006 can converge\n",
    "        self.w = 100\n",
    "\n",
    "\n",
    "    def set_tfweight(self, weight):\n",
    "        \"\"\"Set weight on time\"\"\"\n",
    "        self.tfweight = weight\n",
    "\n",
    "    def construct_prob(self, x0_pack, xf_pack, poly_order, obj_order, connect_order):\n",
    "        \"\"\"Construct a problem.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_x0_pack_value(self, *args):\n",
    "        \"\"\"Set the contents of x0pack\"\"\"\n",
    "        ff = zip(self.x0_pack, args)\n",
    "        print(ff)\n",
    "        for tmp, val in zip(self.x0_pack, args):\n",
    "            tmp[:] = val[:]\n",
    "\n",
    "    def set_xf_pack_value(self, *args):\n",
    "        \"\"\"Set the contents of xfpack\"\"\"\n",
    "        for tmp, val in zip(self.xf_pack, args):\n",
    "            tmp[:] = val[:]\n",
    "\n",
    "    def solve_with_room_time(self, rm_time):\n",
    "        \"\"\"Specify room time and solve the problem\"\"\"\n",
    "        raise NotImplementedError(\"Subclass should implement solve_with_room_time function\")\n",
    "\n",
    "    def get_output_coefficients(self, ):\n",
    "        \"\"\"\n",
    "        Get the monomial coefficients representing a piece-wise polynomial trajectory\n",
    "        return ndarray, (s, 1), time allocated for each segment \n",
    "        return ndarray, (s, o + 1, d), polynomial coefficients, where s is the number of segments, \n",
    "        o is the order of trajectory, d is the number of dimensions, which is 3\n",
    "        \"\"\"\n",
    "        \n",
    "        n_room = self.num_box\n",
    "        \n",
    "        poly_coef = np.zeros([n_room, self.poly_order + 1, 3])\n",
    "        \n",
    "        # coefficients in bezier and scaled form\n",
    "        mat_x = np.reshape(self.sol, (n_room, 3, self.poly_order + 1))\n",
    "        mat_x = np.transpose(mat_x, (0, 2, 1))\n",
    "\n",
    "        # change coefficients to monomial and unscaled form\n",
    "        for i in range(n_room):\n",
    "            poly_coef[i, :, :] = self.bzM.dot(mat_x[i]) * self.room_time[i]\n",
    "\n",
    "        return self.room_time.copy(), poly_coef\n",
    "\n",
    "    def get_coef_matrix(self):\n",
    "        \"\"\"Return coefficients\"\"\"\n",
    "        # self.sol = np.zeros((self.num_box*3*(self.poly_order + 1)))\n",
    "        coef_mat = np.reshape(self.sol, (self.num_box, 3, self.poly_order + 1))\n",
    "        coef_mat = np.transpose(coef_mat, (0, 2, 1))\n",
    "        #import pdb; pdb.set_trace()\n",
    "        for i in range(self.num_box):\n",
    "            coef_mat[i] *= self.room_time[i]\n",
    "        return coef_mat\n",
    "\n",
    "    def get_coef_matrix2(self):\n",
    "        \"\"\"\n",
    "        Return Bezier coefficients\n",
    "        \"\"\"\n",
    "        # self.sol = np.zeros((self.num_box*3*(self.poly_order + 1)))\n",
    "        coef_mat = np.reshape(self.sol, (self.poly_order + 1, 3, self.num_box), order='F')\n",
    "        coef_mat = coef_mat.transpose((0,2,1))\n",
    "        #import pdb;pdb.set_trace()\n",
    "        for i in range(self.num_box):\n",
    "            coef_mat[:,i,:] *= self.room_time[i]\n",
    "        \n",
    "        return coef_mat\n",
    "\n",
    "\n",
    "    def from_coef_matrix(self, mat_in):\n",
    "        \"\"\"Assign values to sol based on the input coefficient matrix.\"\"\"\n",
    "        self.sol = np.zeros(mat_in.size)\n",
    "        coef_mat = np.reshape(self.sol, (self.num_box, 3, self.poly_order + 1))\n",
    "        for i in range(self.num_box):\n",
    "            coef_mat[i] = mat_in[i].T / self.room_time[i]\n",
    "        with np.printoptions(precision=4, linewidth=10000):\n",
    "            print(self.sol)\n",
    "\n",
    "    def get_output_path(self, n):\n",
    "        \"\"\"Get a path for output that is linspace in time.\n",
    "\n",
    "        :param n: int, the number of nodes for a path\n",
    "        :return: float, the total time for this problem\n",
    "        :return: ndarray, (n, 2) the optimal path\n",
    "        \"\"\"\n",
    "        cum_sum_time = np.cumsum(self.room_time)\n",
    "        output = np.zeros((n, 3))  # the output trajectory\n",
    "        sample_time = np.linspace(0, cum_sum_time[-1], n)\n",
    "        n_room = self.num_box\n",
    "\n",
    "        # get all the coef of polynomials\n",
    "        t, all_poly_coeffs = self.get_output_coefficients()\n",
    "        for i in range(n_room):\n",
    "            # poly_coef = self.bzM.dot(mat_x[i]) * self.room_time[i]\n",
    "            poly_coef = all_poly_coeffs[i,:,:]\n",
    "            if i == 0:\n",
    "                t_mask = sample_time <= cum_sum_time[0]\n",
    "                use_s = sample_time[t_mask] / cum_sum_time[0]\n",
    "            else:\n",
    "                t_mask = (sample_time > cum_sum_time[i - 1]) & (sample_time <= cum_sum_time[i])\n",
    "                use_s = (sample_time[t_mask] - cum_sum_time[i - 1]) / self.room_time[i]\n",
    "            output[t_mask, 0] = np.polyval(poly_coef[:, 0][::-1], use_s)\n",
    "            output[t_mask, 1] = np.polyval(poly_coef[:, 1][::-1], use_s)\n",
    "            output[t_mask, 2] = np.polyval(poly_coef[:, 2][::-1], use_s)\n",
    "        return cum_sum_time[-1], output\n",
    "\n",
    "    def get_gradient(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_gradient_fd(self, h=1e-6):\n",
    "        \"\"\"Use forward finite difference to approximate gradients.\"\"\"\n",
    "        grad = np.zeros(self.num_box)\n",
    "        obj0 = self.obj\n",
    "        origin_time = self.room_time.copy()\n",
    "        for i in range(self.num_box):\n",
    "            try_time = origin_time.copy()\n",
    "            try_time[i] += h\n",
    "            self.solve_with_room_time(try_time)\n",
    "            grad[i] = (self.obj - obj0) / h\n",
    "        grad += self.tfweight\n",
    "        return grad\n",
    "\n",
    "    def get_gradient_mellinger(self, h=1e-6):\n",
    "        \"\"\"\n",
    "        Use finite difference described in:\n",
    "        http://www-personal.acfr.usyd.edu.au/spns/cdm/papers/Mellinger.pdf\n",
    "        to approximate gradients.\n",
    "        \"\"\"\n",
    "        grad = np.zeros(self.num_box)\n",
    "        obj0 = self.obj\n",
    "        origin_time = self.room_time.copy()\n",
    "        for i in range(self.num_box):\n",
    "            m = self.num_box\n",
    "            gi = -1/(m-1) * np.ones(m)\n",
    "            gi[i] = 1\n",
    "            try_time = origin_time.copy()\n",
    "            try_time += h * gi\n",
    "            # print(\"In gg Mellinger: gi\", gi,\" try_time: \", try_time)\n",
    "            self.solve_with_room_time(try_time)\n",
    "            grad[i] = (self.obj - obj0) / h\n",
    "        grad += self.tfweight\n",
    "        return grad\n",
    "\n",
    "    def draw3D(self):\n",
    "        # plot 3D trajectory\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        boxes = tgp.getCorridor()\n",
    "\n",
    "        poly_coef = solver.get_coef_matrix().transpose((1,0,2))\n",
    "        break_points = np.insert(np.cumsum(solver.room_time), 0, 0.0)\n",
    "        initial_trajectory = BPoly(poly_coef, break_points)\n",
    "        tt_initial = np.linspace(0.0, break_points[-1], 100)\n",
    "\n",
    "        # poly_coef = solver.get_coef_matrix2()\n",
    "        # final_trajectory = BPoly(poly_coef, break_points)\n",
    "        # tt_final = np.linspace(0.0, break_points[-1], 100)\n",
    "\n",
    "        from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "\n",
    "\n",
    "        def set_axes_equal(ax):\n",
    "            '''Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "            cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
    "            ax.set_aspect('equal') and ax.axis('equal') not working for 3D.\n",
    "\n",
    "            Input\n",
    "            ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "            '''\n",
    "\n",
    "            x_limits = ax.get_xlim3d()\n",
    "            y_limits = ax.get_ylim3d()\n",
    "            z_limits = ax.get_zlim3d()\n",
    "\n",
    "            x_range = abs(x_limits[1] - x_limits[0])\n",
    "            x_middle = np.mean(x_limits)\n",
    "            y_range = abs(y_limits[1] - y_limits[0])\n",
    "            y_middle = np.mean(y_limits)\n",
    "            z_range = abs(z_limits[1] - z_limits[0])\n",
    "            z_middle = np.mean(z_limits)\n",
    "\n",
    "            # The plot bounding box is a sphere in the sense of the infinity\n",
    "            # norm, hence I call half the max range the plot radius.\n",
    "            plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "            ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "            ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "            ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            vertices = boxes[i].vertex\n",
    "            ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], s=1)\n",
    "            Z = vertices            \n",
    "            verts = [[Z[0],Z[1],Z[2],Z[3]],\n",
    "                        [Z[4],Z[5],Z[6],Z[7]], \n",
    "                        [Z[0],Z[1],Z[5],Z[4]], \n",
    "                        [Z[2],Z[3],Z[7],Z[6]], \n",
    "                        [Z[1],Z[2],Z[6],Z[5]],\n",
    "                        [Z[4],Z[7],Z[3],Z[0]], \n",
    "                        [Z[2],Z[3],Z[7],Z[6]]]\n",
    "\n",
    "            # plot safe corridor\n",
    "            pc = Poly3DCollection(verts, alpha = 0.0, facecolor='gray', linewidths=0.1, edgecolors='red')\n",
    "            ax.add_collection3d(pc)\n",
    "\n",
    "        ax.plot(initial_trajectory(tt_initial)[:,0], initial_trajectory(tt_initial)[:,1], initial_trajectory(tt_initial)[:,2], label=\"Before refinement\")\n",
    "        # ax.plot(final_trajectory(tt_final)[:,0], final_trajectory(tt_final)[:,1], final_trajectory(tt_final)[:,2], label=\"After refinement\")\n",
    "\n",
    "        ax.scatter(tgp.position[0,0], tgp.position[0,1], tgp.position[0,2], marker=\"*\", s=20, label=\"Start\")\n",
    "        ax.scatter(tgp.position[1,0], tgp.position[1,1], tgp.position[1,2], marker=\"o\", s=20, label=\"Goal\")\n",
    "        set_axes_equal(ax)\n",
    "        ax.set_axis_off()\n",
    "        ax.legend()\n",
    "        ax.set_title(\"3D trajectory\")\n",
    "\n",
    "        \"\"\"Formulate the indoor navigation problem explicitly as QP so we can either use mosek or osqp to solve it.\n",
    "\n",
    "    I will manually maintain those matrices and hope it is more efficient.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def update_prob(self):\n",
    "        \"\"\"Just update the problem since we are changing pretty fast.\n",
    "\n",
    "        This function assume you might have change in room sequence so it reconstructs things. Take care with this.\n",
    "        \"\"\"\n",
    "        self.construct_prob(self.x0_pack, self.xf_pack, self.poly_order, self.obj_order, self.connect_order)\n",
    "\n",
    "    def construct_prob(self, x0_pack, xf_pack, poly_order, obj_order, connect_order):\n",
    "        \"\"\"Construct a problem.\"\"\"\n",
    "        # construct the problem using Fei's code\n",
    "        # self.construct_P()\n",
    "        self.construct_A()\n",
    "\n",
    "    def construct_P(self):\n",
    "        # P is fixed and we do not alter it afterwards, so let's keep going\n",
    "\n",
    "        pval, prow, pcol = construct_P(self.obj_order, self.num_box, self.poly_order, self.room_time, self.MQM, self.h_type)\n",
    "        self.sp_P = coo_matrix((pval, (prow, pcol)))  # ugly hack since osqp only support upper triangular part or full\n",
    "        self.n_var = self.sp_P.shape[0]\n",
    "        # self.qp_P = spmatrix(sp_P.data, sp_P.row, sp_P.col)\n",
    "        self.qp_q = np.zeros(self.n_var)\n",
    "\n",
    "    def construct_A(self):\n",
    "        lincon = construct_A(\n",
    "                self.floor.getCorridor(),\n",
    "                self.MQM,\n",
    "                self.floor.position.copy(order='F'),\n",
    "                self.floor.velocity.copy(order='F'),\n",
    "                self.floor.acceleration.copy(order='F'),\n",
    "                self.floor.maxVelocity,\n",
    "                self.floor.maxAcceleration,\n",
    "                self.floor.trajectoryOrder,\n",
    "                self.floor.minimizeOrder,\n",
    "                self.floor.margin,\n",
    "                self.floor.doLimitVelocity,\n",
    "                self.floor.doLimitAcceleration)\n",
    "        self.xlb = lincon.xlb\n",
    "        self.xub = lincon.xub\n",
    "        self.clb = lincon.clb\n",
    "        self.cub = lincon.cub\n",
    "        # we need more\n",
    "        self.sp_A = coo_matrix((lincon.aval, (lincon.arow, lincon.acol)))\n",
    "        self.n_con = self.sp_A.shape[0]\n",
    "        if self.verbose > 1:\n",
    "            print('n_con', self.n_con)\n",
    "            print('n_var', self.sp_A.shape[1])\n",
    "            print(\"A has %d nnz\" % lincon.aval.shape[0])\n",
    "\n",
    "    def eval_cost_constr(self, mat_in):\n",
    "        \"\"\"Pass in a coefficient matrix, see results.\"\"\"\n",
    "        self.from_coef_matrix(mat_in)  # update self.sol\n",
    "        self.update_prob()\n",
    "        cost = 0.5 * self.sol.dot(self.sp_P.dot(self.sol))\n",
    "        Ax = self.sp_A.dot(self.sol)\n",
    "        # equality part\n",
    "        error_clb = np.minimum(Ax - self.clb, 0)\n",
    "        error_cub = np.minimum(-Ax + self.cub, 0)\n",
    "        error_lb = np.minimum(self.sol - self.xlb, 0)\n",
    "        error_ub = np.minimum(self.xub - self.sol, 0)\n",
    "        with np.printoptions(precision=4, linewidth=10000):\n",
    "            print('cost %f' % cost)\n",
    "            print('error_eq', np.minimum(error_clb, error_cub))\n",
    "            print('error_ieq', np.minimum(error_lb, error_ub))\n",
    "\n",
    "    def get_gradient(self, sol, lmdy, lmdz):\n",
    "        pgrad = gradient_from_P(self.obj_order, self.num_box, self.poly_order, self.room_time, self.MQM, sol)\n",
    "        agrad = gradient_from_A(\n",
    "                    self.floor.getCorridor(),\n",
    "                    self.MQM,\n",
    "                    self.floor.position.copy(order='F'),\n",
    "                    self.floor.velocity.copy(order='F'),\n",
    "                    self.floor.acceleration.copy(order='F'),\n",
    "                    self.floor.maxVelocity,\n",
    "                    self.floor.maxAcceleration,\n",
    "                    self.floor.trajectoryOrder,\n",
    "                    self.floor.minimizeOrder,\n",
    "                    self.floor.margin,\n",
    "                    self.floor.doLimitVelocity,\n",
    "                    self.floor.doLimitAcceleration,\n",
    "                    sol,\n",
    "                    lmdy,\n",
    "                    lmdz)\n",
    "        if self.verbose > 1:\n",
    "            print('pgrad', pgrad)\n",
    "            print('agrad', agrad)\n",
    "        return pgrad + agrad + self.tfweight\n",
    "\n",
    "    def solve_once(self):\n",
    "        \"\"\"Solve the original problem once.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "    def solve_with_room_time(self, rm_time): ###new candidate time y\n",
    "        self.room_time[:] = rm_time\n",
    "        self.floor.updateCorridorTime(self.room_time)\n",
    "        return self.solve_once()\n",
    "    \n",
    "        \n",
    "\n",
    "    def Monopoly(self, alpha0=0.02, h=1e-5, c=0.2, tau=0.2, max_iter=5000, j_iter=5, log=False, timeProfile=False, adaptiveLineSearch=False):\n",
    "        \"\"\"Use backtrack line search to refine time. We fix total time to make things easier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha0: float, initial step length 0.175 and 0.375 are found to be very good.\n",
    "        h: float, step size for finding gradient using forward differentiation\n",
    "        c: float, the objective decrease parameter\n",
    "        tau: float, the step length shrink parameter\n",
    "        max_iter: int, maximum iteration for gradient descent\n",
    "        j_iter: int, maximum iteration for finding alpha\n",
    "        abs_tol: float, absolute objective tolerance\n",
    "        rel_tol: float, Relative objective tolerance\n",
    "        Returns\n",
    "        -------\n",
    "        is_okay: bool, indicates if some exception occurs\n",
    "        converged: bool, indicates if the algorithm converges\n",
    "        \"\"\"\n",
    "\n",
    "        if log == True:\n",
    "            self.log = np.array([])\n",
    "            self.log = np.append(self.log, [self.obj, 0])\n",
    "\n",
    "        if timeProfile == True:\n",
    "            self.timeProfile = np.array([])\n",
    "\n",
    "        t0 = time.time()\n",
    "        self.major_iteration = 0\n",
    "        self.num_prob_solve = 0\n",
    "        if self.num_box == 1 and self.tfweight == 0:\n",
    "            self.major_iteration = 0\n",
    "            self.num_prob_solve = 0\n",
    "            self.time_cost = time.time() - t0\n",
    "            self.converge_reason = 'No need to refine'\n",
    "            return True, True\n",
    "        n_room = self.num_box\n",
    "        # t_now = self.room_time.copy()\n",
    "        y = torch.from_numpy(self.room_time)\n",
    "        y.requires_grad_()\n",
    "\n",
    "        converged = False\n",
    "        converge_reason = 'Not converged'\n",
    "        num_prob_solve = 0  # record number of problems being solved for a BTLS\n",
    "        T = 3\n",
    "        dim = 3*self.num_box*(self.poly_order+1)\n",
    "        # c_0 = torch.zeros(dim, dtype=torch.double,requires_grad=True)\n",
    "        c_0 = torch.tensor(dim*[0], dtype=torch.double,requires_grad=True)\n",
    "\n",
    "\n",
    "        obj = torch.zeros(1, dtype=torch.double,requires_grad=True)\n",
    "        for i in range(max_iter):\n",
    "            y.requires_grad_()\n",
    "            if self.verbose:\n",
    "                print_green('Iteration %d' % i)\n",
    "           \n",
    "            obj0 = obj\n",
    "            is_okay = True\n",
    "            \n",
    "            if timeProfile == True:\n",
    "                tBeforeGrad = time.time()\n",
    "\n",
    "            self.floor.updateCorridorTime(y.detach().numpy())\n",
    "            IndoorOptProblem.update_prob(self) #update y for c\n",
    "            c = c_0\n",
    "            qval, qrow, qcol = Hierarchy_free.construct_P_matrix(self.obj_order, self.num_box, self.poly_order, y, self.MQM, self.h_type)\n",
    "            # p_y = torch.sparse_coo_tensor((qrow, qcol), qval).to_sparse_csr()\n",
    "            # p_y = torch.sparse_coo_tensor((qrow, qcol), qval).to_dense()\n",
    "            # pp = torch.sparse_coo_tensor((qrow, qcol), qval)\n",
    "            p_y = torch.sparse_coo_tensor((qrow, qcol), qval).to_dense()\n",
    "\n",
    "            # p_y = pp.to_dense()\n",
    "            p_y = p_y + p_y.t() - torch.diag(p_y.diagonal())\n",
    "            #y = torch.from_numpy(self.room_time)\n",
    "            #y.requires_grad_()\n",
    "            \n",
    "            i = 0\n",
    "            while i < T:\n",
    "                c = Hierarchy_free.h(self, p_y, y, c)\n",
    "                i += 1\n",
    "    \n",
    "            # print(np.shape(Hierarchy_free.solve_Jacobian(y,c))) \n",
    "             \n",
    "            obj = Hierarchy_free.l(self, p_y, y, c)\n",
    "            print(obj)\n",
    "            obj.backward()  \n",
    "            grad = y.grad.detach().numpy()\n",
    "\n",
    "            candidit_y= y.detach().numpy()\n",
    "            # choose a method to calculate gradient\n",
    "            # if self.grad_method == 'ours':\n",
    "            #     grad = y.grad\n",
    "            # elif self.grad_method == 'fd':\n",
    "            #     grad = self.get_gradient_fd(h=0.25*1e-6)\n",
    "            # elif self.grad_method == 'mel':\n",
    "            #     grad = self.get_gradient_mellinger(h=0.25*1e-6)\n",
    "            # else:\n",
    "            #     print_red(\"No this grad method!\")\n",
    "            \n",
    "            if timeProfile == True:\n",
    "                tAfterGrad = time.time()\n",
    "                self.timeProfile = np.append(self.timeProfile, [tAfterGrad - tBeforeGrad])\n",
    "\n",
    "            #print_red('grad_an ', grad, ' grad_fd ', grad_fd, 'grad_mel', grad_mel)\n",
    "            if self.tfweight == 0:\n",
    "                # get projected gradient, the linear manifold is \\sum x_i = 0; if tfweight=0, we fix total time\n",
    "                normal = np.ones(n_room) / np.sqrt(n_room) # normal direction\n",
    "                grad = grad - grad.dot(normal) * normal  # projected gradient descent direction\n",
    "            # print_red('grad_an ', grad / np.linalg.norm(grad), ' grad_fd ', grad_fd / np.linalg.norm(grad_fd), 'grad_mel', grad_mel / np.linalg.norm(grad_mel))\n",
    "            # print_yellow('sum_an ', np.sum(grad), 'sum_fd ', np.sum(grad_fd), 'sum_mel ', np.sum(grad_mel))\n",
    "            if np.linalg.norm(grad) < self.grad_tol:  # break out if gradient is too small\n",
    "                if self.verbose:\n",
    "                    print('Gradient too small')\n",
    "                converged = True\n",
    "                converge_reason = 'Small gradient'\n",
    "                break\n",
    "            if self.verbose:\n",
    "                print_green('At time ', candidit_y, ' grad is ', grad)\n",
    "            m = -np.linalg.norm(grad)\n",
    "            p = grad / m  # p is the descending direction\n",
    "            # use a maximum alpha that makes sure time are always positive\n",
    "            alpha_max = np.amax(-candidit_y / p) - 1e-6  # so I still get non-zero things\n",
    "            if alpha_max > 0:\n",
    "                alpha = min(alpha_max, alpha0)\n",
    "            else:\n",
    "                alpha = alpha0\n",
    "            # t = -c * m\n",
    "\n",
    "            # find alpha\n",
    "            alpha_found = False\n",
    "\n",
    "            if timeProfile == True:\n",
    "                tBeforeAlpha = time.time()\n",
    "\n",
    "            for j in range(j_iter):\n",
    "                if self.verbose:\n",
    "                    print('Search alpha step %d, alpha = %f' % (j, alpha))\n",
    "                candidit_y = candidit_y + alpha * p\n",
    "\n",
    "                # lower bound on the alpha\n",
    "                if adaptiveLineSearch == True:\n",
    "                    if alpha < 1e-4:\n",
    "                        if self.verbose:\n",
    "                            print_yellow('Stop line search because alpha is too small')\n",
    "                        break\n",
    "                \n",
    "                # make sure that time will not go too small\n",
    "                if np.any(candidit_y < 1e-6):\n",
    "                    alpha = tau * alpha\n",
    "                    continue\n",
    "                alpha_found = True\n",
    "                break\n",
    "                \n",
    "\n",
    "            if timeProfile == True:\n",
    "                tAfterAlpha = time.time()\n",
    "                self.timeProfile = np.append(self.timeProfile, [tAfterAlpha - tBeforeAlpha])\n",
    "\n",
    "            if self.verbose:\n",
    "                if alpha_found:\n",
    "                    print('We found alpha = %f' % alpha)\n",
    "                else:\n",
    "                    print('Fail to find alpha, use a conservative %f' % alpha)\n",
    "            if not alpha_found:  # for case where alpha is not found\n",
    "                converge_reason = 'Cannot find step size alpha'\n",
    "                is_okay = True\n",
    "                converged = False\n",
    "                # roll back to t_now\n",
    "                self.room_time = candidit_y\n",
    "                if log == True:\n",
    "                    duration = time.time() - t0\n",
    "                    self.log = np.append(self.log, [obj0, duration])\n",
    "                break\n",
    "\n",
    "            # adaptive line search\n",
    "\n",
    "            # ready to update time now and check convergence\n",
    "            with torch.no_grad():\n",
    "                beta = 0.0001\n",
    "                y = torch.from_numpy(candidit_y)\n",
    "                c_pre = c_0\n",
    "                c_0 -= beta * c_0.grad\n",
    "            # y.grad.zero_()\n",
    "            # this is the alpha we desire\n",
    "            if self.verbose:\n",
    "                print('obj0 = ', obj0, 'obj = ', obj)\n",
    "            if log == True:\n",
    "                duration = time.time() - t0\n",
    "                # we log the objective and duration for each major iteration\n",
    "                if self.verbose == True:\n",
    "                    print(\"Logging: obj: %f, T: %f\" % (obj, duration))\n",
    "                self.log = np.append(self.log, [obj, duration])\n",
    "            if abs(obj - obj0) < self.abs_obj_tol:\n",
    "                if self.verbose:\n",
    "                    print('Absolute obj improvement too small')\n",
    "                converged = True\n",
    "                converge_reason = 'Absolute cost'\n",
    "                break\n",
    "            elif abs(obj - obj0) / abs(obj0) < self.rel_obj_tol:\n",
    "                if self.verbose:\n",
    "                    print('Relative obj improvement too small')\n",
    "                converged = True\n",
    "                converge_reason = 'Relative cost'\n",
    "                break\n",
    "        self.major_iteration = i\n",
    "        self.num_prob_solve = num_prob_solve\n",
    "        self.time_cost = time.time() - t0\n",
    "        self.converge_reason = converge_reason\n",
    "        return is_okay, converged\n",
    "\n",
    "\n",
    "    def Cournot(self, alpha0=0.001, h=1e-5, c=0.2, tau=0.1, max_iter=1000, j_iter=50, log=False, timeProfile=False, adaptiveLineSearch=False):\n",
    "        \"\"\"Use backtrack line search to refine time. We fix total time to make things easier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha0: float, initial step length 0.175 and 0.375 are found to be very good.\n",
    "        h: float, step size for finding gradient using forward differentiation\n",
    "        c: float, the objective decrease parameter\n",
    "        tau: float, the step length shrink parameter\n",
    "        max_iter: int, maximum iteration for gradient descent\n",
    "        j_iter: int, maximum iteration for finding alpha\n",
    "        abs_tol: float, absolute objective tolerance\n",
    "        rel_tol: float, Relative objective tolerance\n",
    "        Returns\n",
    "        -------\n",
    "        is_okay: bool, indicates if some exception occurs\n",
    "        converged: bool, indicates if the algorithm converges\n",
    "        \"\"\"\n",
    "\n",
    "        if log == True:\n",
    "            self.log = np.array([])\n",
    "            self.log = np.append(self.log, [self.obj, 0])\n",
    "\n",
    "        if timeProfile == True:\n",
    "            self.timeProfile = np.array([])\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        self.major_iteration = 0\n",
    "        self.num_prob_solve = 0\n",
    "        if self.num_box == 1 and self.tfweight == 0:\n",
    "            self.major_iteration = 0\n",
    "            self.num_prob_solve = 0\n",
    "            self.time_cost = time.time() - t0\n",
    "            self.converge_reason = 'No need to refine'\n",
    "            return True, True\n",
    "        n_room = self.num_box\n",
    "        # t_now = self.room_time.copy()\n",
    "        y = torch.tensor(self.room_time, dtype=torch.double) #, dtype = torch.double\n",
    "\n",
    "        y.requires_grad_()\n",
    "\n",
    "        converged = False\n",
    "        converge_reason = 'Not converged'\n",
    "        num_prob_solve = 0  # record number of problems being solved for a BTLS\n",
    "        T = 500\n",
    "        dim = 3*self.num_box*(self.poly_order+1)\n",
    "        # c_0 = torch.zeros(dim, dtype=torch.double,requires_grad=True)\n",
    "        c_0 = torch.tensor(dim*[0], dtype=torch.double,requires_grad=True)\n",
    "        self.floor.updateCorridorTime(y.detach().numpy())\n",
    "        IndoorOptProblem.update_prob(self) #update y for c\n",
    "        # c_0 = torch.tensor([(self.xlb+self.xub)/2], dtype=torch.double,requires_grad=True)\n",
    "\n",
    "        \n",
    "        # print(\"test:\"+str(Hierarchy_free.l(self, p_y, y, c_0)))\n",
    "        # print(p_y)\n",
    "        obj = torch.zeros(1, dtype=torch.double,requires_grad=True)\n",
    "        for k in range(max_iter):\n",
    "            if self.verbose:\n",
    "                print_green('Iteration %d' % i)\n",
    "           \n",
    "            obj0 = obj\n",
    "            is_okay = True\n",
    "            \n",
    "            if timeProfile == True:\n",
    "                tBeforeGrad = time.time()\n",
    "            \n",
    "            # y = torch.tensor([3.80504758, 1.14997985, 0.83818007],dtype=torch.double)\n",
    "            y.requires_grad_()\n",
    "            self.floor.updateCorridorTime(y.detach().numpy())\n",
    "            IndoorOptProblem.update_prob(self) #update y for c\n",
    "\n",
    "            c = c_0\n",
    "            # tt = time.time()\n",
    "            qval, qrow, qcol = Hierarchy_free.construct_P_matrix(self.obj_order, self.num_box, self.poly_order, y, self.MQM, self.h_type) # time cost: 0.03\n",
    "            # print(time.time()-tt)\n",
    "            \n",
    "            # tt = time.time() \n",
    "            p_y = torch.sparse_coo_tensor((qrow, qcol), qval).to_dense()   # time cost: 0.03\n",
    "            # print(time.time()-tt)\n",
    "            #print(\"hello world: \" ,qrow)\n",
    "            # p_y = pp.to_dense()\n",
    "            p_y = p_y + p_y.t() - torch.diag(p_y.diagonal())\n",
    "\n",
    "            i = 0\n",
    "            while i < T:\n",
    "                # tt = time.time()\n",
    "                c = Hierarchy_free.h(self, p_y, y, c)    # time cost: 0.05\n",
    "                # print(time.time()-tt)          \n",
    "                i += 1\n",
    "            \n",
    "             \n",
    "            obj = Hierarchy_free.l(self, p_y, y, c)\n",
    "            # print(\"obj:\")\n",
    "            print(obj)\n",
    "            self.sol = c.detach().numpy()\n",
    "            self.room_time = y.detach().numpy()\n",
    "            if(k==0):\n",
    "                IndoorOptProblem.draw3D(self)\n",
    "            obj.backward()  \n",
    "            grad = y.grad.detach().numpy()\n",
    "\n",
    "            candidit_y= y.detach().numpy()\n",
    "            # choose a method to calculate gradient\n",
    "            # if self.grad_method == 'ours':\n",
    "            #     grad = y.grad\n",
    "            # elif self.grad_method == 'fd':\n",
    "            #     grad = self.get_gradient_fd(h=0.25*1e-6)\n",
    "            # elif self.grad_method == 'mel':\n",
    "            #     grad = self.get_gradient_mellinger(h=0.25*1e-6)\n",
    "            # else:\n",
    "            #     print_red(\"No this grad method!\")\n",
    "            \n",
    "            if timeProfile == True:\n",
    "                tAfterGrad = time.time()\n",
    "                self.timeProfile = np.append(self.timeProfile, [tAfterGrad - tBeforeGrad])\n",
    "\n",
    "            #print_red('grad_an ', grad, ' grad_fd ', grad_fd, 'grad_mel', grad_mel)\n",
    "            if self.tfweight == 0:\n",
    "                # get projected gradient, the linear manifold is \\sum x_i = 0; if tfweight=0, we fix total time\n",
    "                normal = np.ones(n_room) / np.sqrt(n_room) # normal direction\n",
    "                grad = grad - grad.dot(normal) * normal  # projected gradient descent direction\n",
    "            # print_red('grad_an ', grad / np.linalg.norm(grad), ' grad_fd ', grad_fd / np.linalg.norm(grad_fd), 'grad_mel', grad_mel / np.linalg.norm(grad_mel))\n",
    "            # print_yellow('sum_an ', np.sum(grad), 'sum_fd ', np.sum(grad_fd), 'sum_mel ', np.sum(grad_mel))\n",
    "            if np.linalg.norm(grad) < self.grad_tol:  # break out if gradient is too small\n",
    "                if self.verbose:\n",
    "                    print('Gradient too small')\n",
    "                converged = True\n",
    "                converge_reason = 'Small gradient'\n",
    "                break\n",
    "            if self.verbose:\n",
    "                print_green('At time ', candidit_y, ' grad is ', grad)\n",
    "            m = np.linalg.norm(grad)\n",
    "            # print(m)\n",
    "            p = grad / m  # p is the descending direction\n",
    "            # use a maximum alpha that makes sure time are always positive\n",
    "            # alpha_max = np.amax(-candidit_y / p) - 1e-6  # so I still get non-zero things\n",
    "            \n",
    "            alpha = alpha0\n",
    "            # t = -c * m\n",
    "\n",
    "            # find alpha\n",
    "            alpha_found = False\n",
    "\n",
    "            if timeProfile == True:\n",
    "                tBeforeAlpha = time.time()\n",
    "\n",
    "            for j in range(j_iter):\n",
    "                if self.verbose:\n",
    "                    print('Search alpha step %d, alpha = %f' % (j, alpha))\n",
    "                #candidit_y = y.detach().numpy() - alpha/math.sqrt(k+1) * p\n",
    "                candidit_y = y.detach().numpy() - alpha * grad / math.sqrt(m)\n",
    "                # lower bound on the alpha\n",
    "                if adaptiveLineSearch == True:\n",
    "                    if alpha < 1e-4:\n",
    "                        if self.verbose:\n",
    "                            print_yellow('Stop line search because alpha is too small')\n",
    "                        break\n",
    "                \n",
    "                # make sure that time will not go too small\n",
    "                if np.any(candidit_y < 1e-6):\n",
    "                    print(\"line search\")\n",
    "                    alpha = tau * alpha\n",
    "                    continue\n",
    "                alpha_found = True\n",
    "                break\n",
    "\n",
    "            if timeProfile == True:\n",
    "                tAfterAlpha = time.time()\n",
    "                self.timeProfile = np.append(self.timeProfile, [tAfterAlpha - tBeforeAlpha])\n",
    "\n",
    "            if self.verbose:\n",
    "                if alpha_found:\n",
    "                    print('We found alpha = %f' % alpha)\n",
    "                else:\n",
    "                    print('Fail to find alpha, use a conservative %f' % alpha)\n",
    "            if not alpha_found:  # for case where alpha is not found\n",
    "                converge_reason = 'Cannot find step size alpha'\n",
    "                is_okay = True\n",
    "                converged = False\n",
    "                # roll back to t_now\n",
    "                self.room_time = candidit_y\n",
    "                if log == True:\n",
    "                    duration = time.time() - t0\n",
    "                    self.log = np.append(self.log, [obj0, duration])\n",
    "                break\n",
    "\n",
    "            # adaptive line search\n",
    "\n",
    "            # ready to update time now and check convergence\n",
    "            with torch.no_grad():\n",
    "                c_0 = Hierarchy_free.h(self, p_y, y, c)\n",
    "                y = torch.from_numpy(candidit_y)\n",
    "            # y.grad.zero_()\n",
    "            # this is the alpha we desire\n",
    "            if self.verbose:\n",
    "                print('obj0 = ', obj0, 'obj = ', obj)\n",
    "            if log == True:\n",
    "                duration = time.time() - t0\n",
    "                # we log the objective and duration for each major iteration\n",
    "                if self.verbose == True:\n",
    "                    print(\"Logging: obj: %f, T: %f\" % (obj, duration))\n",
    "                self.log = np.append(self.log, [obj, duration])\n",
    "            if abs(obj - obj0) < self.abs_obj_tol:\n",
    "                if self.verbose:\n",
    "                    print('Absolute obj improvement too small')\n",
    "                converged = True\n",
    "                converge_reason = 'Absolute cost'\n",
    "                break\n",
    "            elif abs(obj - obj0) / abs(obj0) < self.rel_obj_tol:\n",
    "                if self.verbose:\n",
    "                    print('Relative obj improvement too small')\n",
    "                converged = True\n",
    "                converge_reason = 'Relative cost'\n",
    "                break\n",
    "            k += 1\n",
    "        self.major_iteration = i\n",
    "        self.num_prob_solve = num_prob_solve\n",
    "        self.time_cost = time.time() - t0\n",
    "        self.converge_reason = converge_reason\n",
    "        return is_okay, converged, converge_reason\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "class IndoorQPProblemMOSEK(IndoorOptProblem):\n",
    "    \"\"\"Use mosek solver to solve this problem in cvxopt interface or not\"\"\"\n",
    "    def __init__(self, tgp, tfweight=0, connect_order=2, verbose=False):\n",
    "        IndoorOptProblem.__init__(self, tgp, tfweight, connect_order, verbose)\n",
    "        self.h_type = \"L\"\n",
    "\n",
    "    def solve_once(self):\n",
    "\n",
    "        self.update_prob()\n",
    "\n",
    "        # set up A\n",
    "        A_sp = self.sp_A.tocsc()\n",
    "        colptr, asub, acof = A_sp.indptr, A_sp.indices, A_sp.data\n",
    "        aptrb, aptre = colptr[:-1], colptr[1:]\n",
    "        # set up bounds on x\n",
    "        bkx = self.n_var * [mosek.boundkey.ra]\n",
    "        bkc = self.n_con * [mosek.boundkey.ra]\n",
    "        with mosek.Env() as env:\n",
    "            with env.Task(0, 1) as task:\n",
    "                task.inputdata(self.n_con, self.n_var, self.qp_q.tolist(), 0.0,\n",
    "                                list(aptrb), list(aptre), list(asub), list(acof),\n",
    "                                bkc, self.clb.tolist(), self.cub.tolist(), \n",
    "                                bkx, self.xlb.tolist(), self.xub.tolist()\n",
    "                                )\n",
    "                # set up lower triangular part of P\n",
    "                task.putqobj(self.sp_P.row.tolist(), self.sp_P.col.tolist(), self.sp_P.data.tolist())\n",
    "                task.putobjsense(mosek.objsense.minimize)\n",
    "                task.optimize()\n",
    "                solsta = task.getsolsta(mosek.soltype.itr)\n",
    "                x = self.n_var * [0.0]\n",
    "                task.getsolutionslice(mosek.soltype.itr, mosek.solitem.xx, 0, self.n_var, x)\n",
    "                x = np.array(x)\n",
    "                # get dual variables on linear constraints\n",
    "                zu, zl = self.n_con * [0.0], self.n_con * [0.0]\n",
    "                task.getsolutionslice(mosek.soltype.itr, mosek.solitem.suc, 0, self.n_con, zu)\n",
    "                task.getsolutionslice(mosek.soltype.itr, mosek.solitem.slc, 0, self.n_con, zl)\n",
    "                z = np.array(zu) - np.array(zl)\n",
    "                # get dual variables on variable bounds\n",
    "                yu, yl = self.n_var * [0.0], self.n_var * [0.0]\n",
    "                task.getsolutionslice(mosek.soltype.itr, mosek.solitem.sux, 0, self.n_var, yu)\n",
    "                task.getsolutionslice(mosek.soltype.itr, mosek.solitem.slx, 0, self.n_var, yl)\n",
    "                y = np.array(yu) - np.array(yl)\n",
    "                if self.verbose:\n",
    "                    print(\"Solving status\", solsta)\n",
    "                if solsta == mosek.solsta.optimal: #solsta == mosek.solsta.near_optimal: near_optimal is longer valid in Mosek 9.0\n",
    "                    self.is_solved = True\n",
    "                    self.obj = task.getprimalobj(mosek.soltype.itr) + self.tfweight * np.sum(self.room_time)\n",
    "                    self.sol = x\n",
    "                    self.lmdy = z\n",
    "                    self.lmdz = y\n",
    "                    return solsta, x, z, y\n",
    "                else:\n",
    "                    self.is_solved = False\n",
    "                    self.obj = np.inf\n",
    "                    #print(\"Mosek Failed, solsta: \", solsta)\n",
    "                    return solsta, None, None, None\n",
    "                \n",
    "class Hierarchy_free(IndoorOptProblem):\n",
    "    \"\"\"Use mosek solver to solve this problem in cvxopt interface or not\"\"\"\n",
    "    def __init__(self, tgp, tfweight=0, connect_order=2, verbose=False):\n",
    "        IndoorOptProblem.__init__(self, tgp, tfweight, connect_order, verbose)\n",
    "        \n",
    "    def construct_P_matrix(minimize_order, segment_num, poly_order, room_time, MQM, ptype):\n",
    "        min_order_l = int(np.floor(minimize_order))\n",
    "        min_order_u = int(np.ceil(minimize_order))\n",
    "\n",
    "        NUMQNZ = 0\n",
    "        NUMQ_blk = poly_order + 1  # default minimize the jerk and minimize_order = 3\n",
    "        if ptype.lower() == \"f\":\n",
    "            NUMQNZ = segment_num * 3 * (NUMQ_blk ** 2)\n",
    "        else:\n",
    "            NUMQNZ = segment_num * 3 * NUMQ_blk * (NUMQ_blk + 1) / 2\n",
    "\n",
    "        qval = torch.zeros(int(NUMQNZ),dtype=torch.double)\n",
    "        qsubi = np.zeros(int(NUMQNZ),dtype=int)\n",
    "        qsubj = np.zeros(int(NUMQNZ),dtype=int)\n",
    "        \n",
    "        sub_shift = 0\n",
    "        idx = 0\n",
    "        s1d1CtrlP_num = poly_order + 1\n",
    "        s1CtrlP_num = 3 * s1d1CtrlP_num\n",
    "\n",
    "        for k in range(segment_num):\n",
    "            scale_k = room_time[k]\n",
    "            for p in range(3):\n",
    "                for i in range(s1d1CtrlP_num):\n",
    "                    for j in range(s1d1CtrlP_num):\n",
    "                        if ((ptype.lower() == \"l\" and i >= j) or (ptype.lower() == \"u\" and i <= j) or ptype.lower() == \"f\"):\n",
    "                            qsubi[idx] = sub_shift + p * s1d1CtrlP_num + i\n",
    "                            qsubj[idx] = sub_shift + p * s1d1CtrlP_num + j\n",
    "\n",
    "                            if min_order_l == min_order_u:\n",
    "                                qval[idx] = MQM[i][j] / (scale_k ** (2 * min_order_u - 3))\n",
    "                            else:\n",
    "                                qval[idx] = ((minimize_order - min_order_l) / (scale_k ** (2 * min_order_u - 3)) +\n",
    "                                            (min_order_u - minimize_order) / (scale_k ** (2 * min_order_l - 3))) * MQM[i][j]\n",
    "                            idx += 1\n",
    "\n",
    "            sub_shift += s1CtrlP_num\n",
    "        # p_coomatrix = torch.sparse_coo_tensor((qsubi, qsubj), qval)\n",
    "        # return p_coomatrix.to_dense()\n",
    "        return qval, qsubi, qsubj\n",
    "\n",
    "    # def df(self, p_y, c): # derivative of lower-level cost with respect to variable c\n",
    "    #     return 2 * p_y @ c\n",
    "    \n",
    "    # def l(self, p_y, y, c):  # loss fsunction\n",
    "\n",
    "    #     return torch.dot(c, p_y @ c) #   + sum(torch.tensor(self.tfweight)* y)\n",
    "\n",
    "\n",
    "    def df(self, p_y, y, c): # derivative of lower-level cost with respect to variable c\n",
    "        sp_A = torch.from_numpy(self.sp_A.toarray())\n",
    "        clb = self.clb\n",
    "        result = 2*p_y @ c.T + 2 * self.w *(sp_A.T @ sp_A @ c.T -sp_A.T @ clb.T)  # 0.0001\n",
    "\n",
    "        # print(2*p_y @ c.T)\n",
    "        # print(2 * self.w *(sp_A.T @ sp_A @ c.T -sp_A.T @ clb.T)) This part is almost 0\n",
    "        return result\n",
    "    \n",
    "    def l(self, p_y, y, c):  # loss function\n",
    "        sp_A = torch.from_numpy(self.sp_A.toarray())\n",
    "        clb = torch.from_numpy(self.clb)\n",
    "        return 0.5 * c @ (p_y@c.T) + self.w * torch.norm(sp_A @ c.T - clb)**2\n",
    "    \n",
    "    def h(self, p_y, y, c):  # solving lower-level problem c\n",
    "\n",
    "        # dim = 3*self.num_box*(self.poly_order+1)\n",
    "        # c_var = cp.Variable(dim)\n",
    "        # b_par = cp.Parameter(dim)\n",
    "        # sp_A = torch.from_numpy(self.sp_A.toarray())\n",
    "        # clb = torch.from_numpy(self.clb)\n",
    "        # # constraints = [self.sp_A @ c_var == self.clb, c_var<=self.xub, c_var>=self.xlb]  #\n",
    "        # constraints = [sp_A @ c_var.T == clb, c_var<=self.xub, c_var>=self.xlb]\n",
    "        # objective = cp.Minimize(cp.pnorm(c_var - b_par, p=2))\n",
    "        # problem = cp.Problem(objective, constraints)\n",
    "        # assert problem.is_dpp()\n",
    "        # # v = time.time()\n",
    "        # f = Hierarchy_free.df(self, p_y, y, c).T\n",
    "        # b = c - self.r * f /(torch.sum(abs(f))+1)\n",
    "        # #b = c - self.r * f\n",
    "        # # print(\"norm_f:\")\n",
    "        # # print(torch.sum(abs(f)))    #/ torch.sum(abs(f))\n",
    "        # # print(\"time df:\"+str(time.time()-v))\n",
    "        # # v = time.time()\n",
    "        # cvxpylayer = CvxpyLayer(problem, parameters=[b_par], variables=[c_var])\n",
    "        # # print(\"time cvlayer:\"+str(time.time()-v))\n",
    "        # c = cvxpylayer(b)[0]\n",
    "        # tt = time.time()\n",
    "        f = Hierarchy_free.df(self, p_y, y, c).T  # time cost: 0.03\n",
    "        #print(time.time()-tt)\n",
    "        # tt = time.time()\n",
    "        b = c- self.r * f /math.sqrt((torch.sum(abs(f))+1)) # time cost: 7e^-5\n",
    "        # print(time.time()-tt)\n",
    "        xlb = torch.from_numpy(self.xlb)  # time cost: e^-6\n",
    "        xub = torch.from_numpy(self.xub)\n",
    "        \n",
    "        b = torch.min(torch.max(b,xlb),xub)  # time cost: e^-5\n",
    "\n",
    "        #obj = Hierarchy_free.l(self, p_y, y, c)  # time cost: 7e^-5\n",
    "        #print(time.time()-tt)\n",
    "        #print(\"obj:\", obj)\n",
    "        \n",
    "        return b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Test the backtrack line search with IP solver.\"\"\"\n",
    "prob = 18  # problem 11 has a small dimension so its more fast, optimise the speed on problem 18\n",
    "\n",
    "tgp = loadTGP('dataset/tgp_%d.tgp' % prob)  # every time you have to reload from hard disk since it is modified before\n",
    "initial_time_allocation = np.array([box.t for box in tgp.getCorridor()])\n",
    "    \n",
    "# we do not limit velocity in the open source implementation\n",
    "tgp.doLimitVelocity = False\n",
    "# we minimize jerk\n",
    "tgp.minimizeOrder = 3\n",
    "# we use 6-th order piecewise Bezier spline\n",
    "tgp.trajectoryOrder = 6\n",
    "    \n",
    "#print_green(\"Use Mosek + Adaptive line search\")\n",
    "    \n",
    "solver = IndoorOptProblem(tgp, verbose=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16548.3037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(11852.7429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9730.3136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8151.1884, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6881.8064, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5946.0999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5157.6245, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4547.1145, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4032.4628, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3610.1499, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3252.2240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2945.5656, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2679.9103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2447.6781, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2242.6392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2059.0579, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1892.7709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1740.9934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1601.7157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1473.3248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1354.6007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1244.5681, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1142.5763, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1048.1252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(960.7947, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(880.3077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(806.3481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(738.5364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(676.3205, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(619.3890, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(567.4694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(520.3418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(477.1406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(438.4429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(403.7436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(372.6181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(344.5464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(319.3111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(296.6453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(276.3217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(258.0868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(241.7359, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(227.0711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(214.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(202.4059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(192.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(182.7498, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(174.4432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(166.9845, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(160.2626, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(154.1464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(148.6320, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(143.5780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(139.3069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(135.3515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(131.6694, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(128.2144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(124.9476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(121.8390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(118.9110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(116.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(113.4782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(110.9562, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(108.5349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(106.1999, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(103.7568, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(101.5018, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(99.4505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(97.5540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(95.7878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(94.1504, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(92.6079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(91.1587, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(89.8063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(88.7513, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(87.7318, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(86.7488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(85.8075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(84.9050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(84.0366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(83.2003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(82.4012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(81.6320, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(80.8930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(80.1842, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(79.5001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(78.8333, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(78.1895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(77.5692, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(76.9658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(76.3761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(75.8030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(75.2463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(74.7054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(74.1660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(73.6468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(73.1483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(72.6471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(72.1676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(71.6854, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(71.2263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(70.7658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(70.3304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(69.8916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(69.4422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(69.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(68.5849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(68.1758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(67.7631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(67.3478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(66.9552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(66.5616, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(66.1660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(65.7908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(65.4165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(65.0480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(64.7079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(64.3664, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(64.0244, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(63.6914, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(63.3610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(63.0338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(62.7132, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(62.3981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(62.0893, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(61.7861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(61.4891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(61.1987, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(60.9148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(60.6382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(60.3625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(60.0944, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(59.8344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(59.5812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(59.3344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(59.0834, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(58.8403, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(58.6049, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(58.3768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(58.1555, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(57.9259, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(57.7047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(57.4916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(57.2860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(57.0872, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(56.8940, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(56.7071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(56.5086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(56.3185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(56.1364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(55.9606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(55.7915, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(55.6287, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(55.4711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(55.2992, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(55.1422, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(54.9853, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(54.8357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(54.6922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(54.5552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(54.4227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(54.3328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(54.1919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(53.9273, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(48.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(40.6376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(38.8791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(36.0679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(33.2941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(31.6757, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(29.3634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(27.8812, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(25.9379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(24.2416, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(23.2951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(21.9913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(21.1645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(20.1881, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(19.3954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(18.5868, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(17.8669, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(17.1248, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(16.5243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(15.9455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(15.2367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(14.7743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(15.0983, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(14.0316, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(13.6095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(14.1511, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(13.1085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(12.6357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(13.3367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(12.3008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(11.7865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(12.6234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(11.5946, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(11.0365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(11.9766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(10.9644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(10.3636, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(11.3687, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(10.3872, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9.7529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(10.8138, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9.8612, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9.1966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(10.3038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9.3800, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.6875, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9.8344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.9383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.2210, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(9.3955, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.5298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.7924, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.9815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.1497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.3971, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.6021, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.8016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.2986, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.5111, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.6790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8.0738, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.2690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.3548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.7702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.9922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.0407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.4794, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.7209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.7473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.2151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.4708, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.9756, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.2442, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.2413, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.7609, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.0418, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.0286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.5718, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.8642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.8419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.4087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.7118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.6808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.2712, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.5839, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.5446, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.1476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.4282, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.1126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.3654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.3252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.4848, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.9122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4204, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.9889, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.8621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.4843, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.6233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.0241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.5077, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.0453, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.6329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.6509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(7.1131, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.3177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.7443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.2473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.8075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.9708, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.7306, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.0454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.5110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.0412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.6284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.8896, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.4920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.1835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.7405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.1534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.7221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.3552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.8994, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.9493, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.5454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.0820, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.6845, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.9113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.9861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.9506, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.0489, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.9911, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.4950, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.0739, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.7091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(6.1658, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.6110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.1407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.7313, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.9663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.3984, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.9258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.5238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.8961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.3033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.8172, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.4096, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.7709, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.1715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.6838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.2801, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.6606, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.2523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.9317, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.6527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.4088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.1714, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.2910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.0795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5.3898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.7711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.2815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.9158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.6126, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.3512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.9366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.7727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.6291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.5072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.3985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.3062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.2227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1521, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0873, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0319, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9804, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9320, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9252, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.9897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.5799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.2807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.8055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.6233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.4690, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.3417, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.2340, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1450, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0036, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9470, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8781, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.0509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.5852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.2550, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.9773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.7430, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.5472, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.3825, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.2469, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8085, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7698, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7086, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6847, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6308, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5886, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.2491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.6974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.2961, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.7553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.5447, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.3689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.2220, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8573, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7575, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6588, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5826, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5496, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5382, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7753, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.9829, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(4.3206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.7788, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.3341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(3.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.7639, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.5458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.3631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.2103, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0837, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8264, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7698, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7227, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6833, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6497, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5758, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5301, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5193, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5007, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4925, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4851, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4783, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4719, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4657, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.9152, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.5741, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.3631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1905, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.0525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9415, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7819, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7242, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6774, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6384, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6056, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5541, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5163, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4887, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4782, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4689, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.2608, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.7206, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.4796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.2863, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(2.1279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.9970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.8055, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.7379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.6013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5209, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.5009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4844, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4695, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4574, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4473, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(1.4379, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True, 'Absolute cost')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver.Cournot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver.draw3D()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
